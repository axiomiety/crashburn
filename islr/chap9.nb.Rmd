---
title: "ISLR Chapter 9"
output:
  html_document:
    df_print: paged
---

# 9.6.1

a non linearly separable dataset:
```{r}
set.seed (1)
x = matrix ( rnorm (20*2) , ncol =2)
y = c ( rep ( -1 ,10) , rep (1 ,10) )
x [ y ==1 ,]= x [ y ==1 ,] + 1
plot (x , col =(3 - y ) )
```
using SVM:
```{r}
dat = data.frame ( x =x , y = as.factor ( y ) )
library ( e1071 )
svmfit = svm( y ~. , scale = FALSE, data = dat , kernel = "linear" , cost =10 )
plot ( svmfit , dat )
```
support vectors:
```{r}
svmfit$index
```
there are 7 of them

```{r}
summary(svmfit)
```
so 4 for -1 and 3 for 1

now the same but with a smaller cost, so margin is wider:
```{r}
svmfit2 = svm( y ~. , scale = FALSE, data = dat , kernel = "linear" , cost =0.1 )
plot ( svmfit2 , dat )
```
tuning

```{r}
set.seed(1)
tune.out = tune( svm , y~. , data = dat , kernel ="linear", ranges = list(cost=c(0.001 , 0.01 , 0.1 , 1 ,5 ,10 ,100)))
summary(tune.out)
```
show the best model:
```{r}
bestmod = tune.out$best.model
summary(bestmod)
```

```{r}
set.seed(1)
xtest = matrix ( rnorm (20*2) , ncol =2)
ytest = sample ( c ( -1 ,1) , 20 , rep = TRUE )
xtest [ ytest ==1 ,]= xtest [ ytest ==1 ,] + 1
testdat = data.frame ( x = xtest , y = as.factor ( ytest ) )
ypred = predict ( bestmod , testdat )
table ( predict = ypred, truth=testdat$y)
```
different cost:
```{r}
svmfit = svm ( y~., data = dat , scale = FALSE, cost=0.01, kernel="linear")
ypred = predict ( svmfit , testdat )
table ( predict = ypred , truth=testdat$y)
```
plot:
```{r}
x[ y ==1 ,]= x [ y ==1 ,]+0.5
plot (x , col =( y +5) /2 , pch =19)
```

obs are barely separable:
```{r}
dat = data.frame( x =x , y = as.factor ( y ) )
svmfit = svm ( y~. , data = dat , kernel="linear", cost=1e+05)
summary ( svmfit )
plot(svmfit, dat)
```
now with a lower cost:

```{r}
svmfit=svm(y~., data=dat, kernel="linear", cost=1)
summary(svmfit)
plot(svmfit,dat)
```

# 9.6.2 Support Vector Machine

```{r}
set.seed (1)
x = matrix ( rnorm (200*2) , ncol=2)
x [1:100 ,]= x [1:100 ,]+2
x [101:150 ,]= x [101:150 ,] -2
y = c ( rep (1 ,150) , rep (2 ,50) )
dat = data.frame ( x =x , y = as.factor ( y ) )
plot(x,col=y)
```
split into test and train
```{r}
train = sample (200 ,100)
svmfit=svm(y~., data = dat [ train ,] , kernel ="radial" , gamma =1 , cost=1)
plot(svmfit, dat[train,])
summary(svmfit)
```

```{r}
svm ( y~. , cost=1e5, data = dat [ train ,] , kernel ="radial" , gamma =1)
plot(svmfit, dat[train,])
```

cross-validation for gamma
```{r}
set.seed(1)
tune.out <- tune(svm, y~., data=dat[train,], kernel="radial", ranges=list(cost=c(0.1,1,10,100,1000)), gamma=c(0.5,1,2,3,4))
summary(tune.out)
```

table:
```{r}
table ( true = dat[ -train ,"y"], pred=predict(tune.out$best.model, newdata = dat[ -train ,]))
```
mis-classification stands at 8%

# 9.6.3 ROC Curves

```{r}
library(ROCR)
rocplot=function(pred, truth, ...) {
  predob = prediction(pred, truth)
  perf = performance(predob, "tpr", "fpr")
  plot(perf, ...)
}
```

we can obtain the fitted values:
```{r}
svmfit.opt <- svm(y~., data = dat[train , ], kernel = "radial", gamma = 2, cost = 1, decision.values = T)
fitted=attributes(predict(svmfit.opt,dat[train,],decision.values=T))$decision.values
par(mfrow=c(1,2))
rocplot(fitted, dat[train,"y"],main="training data")
# changing the gamma - this must be done in the same block, otherwise i get a plot.new hasn't been called error
svmfit.flex=svm(y~.,data=dat[train,], kernel="radial", gamma=50,cost=1,decision.values=T)
fitted=attributes(predict(svmfit.flex,dat[train,], decision.values=T))$decision.values
rocplot(-fitted,dat[train,"y"], add=T,col="red")
```

we can change gamma:
```{r}
svmfit.flex=svm(y~.,data=dat[train,], kernel="radial", gamma=50,cost=1,decision.values=T)
fitted=attributes(predict(svmfit.flex,dat[train,], decision.values=T))$decision.values
rocplot(-fitted,dat[train,"y"], add=T,col="red")
```

let's look at the level of prediction accuracy on the test data:
```{r}
fitted = attributes ( predict ( svmfit.opt , dat [ - train ,] , decision.values=T))$decision.values
rocplot ( fitted , dat [ - train ,"y"] , main =" Test Data ")
fitted = attributes ( predict ( svmfit.flex , dat [ - train ,] , decision.values=T))$decision.values
rocplot(fitted,dat[-train, "y"], add=T,col="red")
```

# 9.6.4 SVM with Multple Classes

$y$ is defined in 9.6.2

```{r}
set.seed (1)
xx=rbind(x,matrix(rnorm(50*2), ncol=2))
yy=c(y,rep(0,50))
xx[yy==0,2]=xx[yy==0,2]+2
dat=data.frame(x=xx,y=as.factor(yy))
par(mfrow=c(1,1))
plot(xx,col=(yy+1))
```

fit:
```{r}
svmfit=svm(y~., data=dat, kernel="radial", cost=10, gamma=1)
plot(svmfit, dat)
```

# 9.6.5 Applicaiton to Gene Expression Data

Khan represents tissue samples, small round blue cell tumours

```{r}
library(ISLR)
names(Khan)
table(Khan$ytrain)
table(Khan$ytest)
```
large number of features vs number of observations -> additional flexibility is unnecessary

```{r}
dat=data.frame(x=Khan$xtrain, y=as.factor(Khan$ytrain))
out=svm(y~., data=dat, kernel="linear", cost=10)
summary(out)
table(out$fitted, dat$y)
```

zero training errors! large number of variables vs observations -> easy to find hyperplanes that fully separate classes

on test obs:
```{r}
dat.te=data.frame(x=Khan$xtest, y=as.factor(Khan$ytest))
pred.te=predict(out, newdata=dat.te)
table(pred.te, dat.te$y)
```

# 9.7.4

 - 2-class data with 100 observations and 2 features, non-linear separation
 - svm using a polynomial kernel vs radial will outperform on training data
 - what about the test data?
 
```{r}
set.seed (13)
x <- matrix(rnorm(100*2), ncol=2)
y <- c(rep(-1, 50), rep(1,50))
x[y==1,1] = x[y==1,1] + 3
x[y==1,2] = x[y==1,2] + 3
# now shift some of the obs down
x[y==1,2] = ifelse(x[y==1,1] > 2, x[y==1,2]-1, x[y==1,2])
plot(x, col =(3-y))
```
training data:

```{r}
train = sample (100,40)
dat = data.frame ( x =x , y = as.factor ( y ) )
svmfit.linear <- svm(y~., data=dat[train,], kernel="linear", cost=1)
# polynomial of deg 3 wasn't too great
#svmfit.radial <- svm(y~., data=dat[train,] ,kernel ="polynomial", degree=3, gamma =1 , cost=1)
svmfit.radial <- svm(y~., data=dat[train,] ,kernel ="radial", gamma =1 , cost=1)
summary(svmfit.linear)
table ( true = dat[ train ,"y"], pred=predict(svmfit.linear, newdata = dat[ train ,]))
summary(svmfit.radial)
table ( true = dat[ train ,"y"], pred=predict(svmfit.radial, newdata = dat[ train ,]))
```

plots:
```{r}
plot(svmfit.linear, dat[train,])
plot(svmfit.radial, dat[train,])
```

on test data:
```{r}
table ( true = dat[ -train ,"y"], pred=predict(svmfit.linear, newdata = dat[ -train ,]))
table ( true = dat[ -train ,"y"], pred=predict(svmfit.radial, newdata = dat[ -train ,]))
```

# 9.7.5

(a)
```{r}
set.seed(123)
x1 = runif (500) -0.5
x2 = runif (500) -0.5
y =1*( x1 ^2 - x2 ^2 > 0)
```

(b)
```{r}
plot(x1,x2, col=3-y)
```
or
```{r}
library(ggplot2)
ggplot(data,
       aes(x1, x2, color = factor(y))) +
  geom_point()
```
(c) logistic reg
```{r}
data <- data.frame(x1,x2,y)
linreg.linear.fit<- glm(y ~ ., family="binomial", data=data)
summary(model.fit)
```

(d) 
```{r}
# we have 200 observations
#train = sample (200,120)
preds <- predict(linreg.linear.fit, data.frame(x1,x2), type="response")
preds_to_classes <- ifelse(preds > 0.5, 1, 0)
ggplot(data,
       aes(x1, x2, color = factor(preds_to_classes))) +
  geom_point()
```

(e) logistic reg, non-linear fns of X_1 and X_2
```{r}
linreg.nonlinear.fit<- glm(y ~ poly(x1,2)+x1*x2+poly(x2,2), family=binomial(), data=data)
```

(f) 
```{r}
preds2 <- predict(linreg.nonlinear.fit, data, type="response")
preds2_to_classes <- ifelse(preds2 > 0.5, 1, 0)
ggplot(data,
       aes(x1, x2, color = factor(preds2_to_classes))) +
  geom_point()
```

(g) support vector classifier - which is an SVM with a linear kernel
```{r}
library(e1071)
svm.linear.fit <- svm(y~., data=data, kernel='linear')
svm.linear.pred <- predict(svm.linear.fit, data, type='response')
preds3_to_classes <- ifelse(svm.linear.pred > 0.5, 1, 0)
ggplot(data,
       aes(x1, x2, color = factor(preds3_to_classes))) +
  geom_point()

```
(h) SVM, non-linear kernel
```{r}
svm.nonlinear.fit <- svm(y~., data=data, kernel='radial')
svm.nonlinear.pred <- predict(svm.nonlinear.fit, data, type='response')
preds4_to_classes <- ifelse(svm.nonlinear.pred > 0.5, 1, 0)
ggplot(data,
       aes(x1, x2, color = factor(preds4_to_classes))) +
  geom_point()

```
(i) commentary!

heh

# 9.7.6

(a)
```{r}
set.seed(456)
x1 <- runif(500)-0.5
x2 <- runif(500)-0.5
y <- ifelse(x1+x2 > 0, 1, 2)
data <- data.frame(x1,x2,y)
ggplot(data,
       aes(x1, x2, color = factor(y))) +
  geom_point()

```

(b)
```{r}
costs <- c(0.001 , 0.01 , 0.1 , 0.5,  1 ,5 ,10 ,20,40,80)
tune.out = tune(svm , y~. , data = data , kernel ="linear", ranges = list(cost=costs))
summary(tune.out)
```

(c)
```{r}
perf <- tune.out$performances
#ggplot(perf, aes(x=cost, y=error)) + 
#  geom_bar()
plot(tune.out$performances[,c(1,2)],type='l')
cc <- function(cost) {
  svmfit = svm ( y~., data = data , scale = FALSE, cost=cost, kernel="linear")
  ypred = predict( svmfit , data, type="response")
  sum(ypred!=data$y)/dim(data)[1]
}

lapply(costs, cc)
```

(d)
```{r}
print("nothing")
```

# 9.7.7

(a) binary var
```{r}
library(ISLR)
data <- Auto
med <- median(Auto$mpg)
# it's a binary classification
data$binvar <- as.factor(ifelse(Auto$mpg > med, 1, 0))
# deleting columns we won't be using
data$mpg <- NULL
data$name <- NULL
table(data$binvar)
```

as expected, half is above the median, the other below.

(b) svc
```{r}
require(e1071)
costs <- c(0.00001,0.0001,0.001,0.01,0.1,1,10,100)
# gammas <- 10^(-5:-1)
tune.out <- tune(svm, binvar ~ ., ranges=list(costs=costs), kernel="linear", data=data, scale=FALSE)
summary(tune.out)
plot(tune.out$best.model, data, weight~horsepower)
```
(c) again but with different gammas too, and various degrees if kernel type = "polynomial"
```{r}
ctrl <- tune.control(
  sampling='cross',   # Do cross-validation (the default)
  cross=10,            # Num folds (default = 10)

  
    nrepeat=1)          # Num repeats (default is 1) 

train.grid <- list(cost=2^(-2:5), gamma=10^(-5:-1), degrees=(2:5))

tuned <- tune(svm, binvar~., data=a, kernel='polynomial',
              ranges = train.grid, tunecontrol = ctrl, scale=FALSE)
summary(tuned)
plot(tuned$best.model, data, weight~horsepower)
```

best was a quadratic polynomial!
```{r}
tuned$best.parameters
```
let's try with radial:
```{r}
train.grid <- list(cost=2^(-2:5), gamma=10^(-5:-1))

tuned <- tune(svm, binvar~., data=a, kernel='radial',
              ranges = train.grid, tunecontrol = ctrl)
summary(tuned)
```
and the best - different cost, same gamma (there's no degree used in radia)
```{r}
tuned$best.parameters
```
(d) adding some plots
```{r}
plot(tuned$best.model, data, weight~horsepower)
```

# 9.7.8

(a) OJ data
```{r}
library(ISLR)
set.seed(89)
attach(OJ)
train <- sample(nrow(OJ), 800)
```

(b) fit a support vector classifier (linear)
```{r}
library(e1071)
svm.fit <- svm(Purchase ~ ., kernel="linear", cost=0.01, data=OJ[train,], scale=FALSE, method="class")
summary(svm.fit)
```
(c) training/testing errors
```{r}
library(caret)
training_pred <- predict(svm.fit, newdata=OJ[train,], type="class")
confusionMatrix(training_pred,OJ[train,]$Purchase)
testing_pred <- predict(svm.fit, newdata=OJ[-train,], type="class")
confusionMatrix(testing_pred,OJ[-train,]$Purchase)
```
(d) using `tune` for optimal cost
```{r}
costs <- 10^seq(-2, 1, by = 0.5)
tune.out <- tune(svm, Purchase ~ ., ranges=list(costs=costs), kernel="linear", data=OJ[train,], scale=FALSE, method="class")
tune.out$best.parameters
```

(e) same as above, but using the optimal cost - which incidentally is what we had?
```{r}
svm.fit <- svm(Purchase ~ ., kernel="linear", cost=tune.out$best.parameters$costs, data=OJ[train,], scale=FALSE, method="class")
training_pred <- predict(svm.fit, newdata=OJ[train,], type="class")
confusionMatrix(training_pred,OJ[train,]$Purchase)
testing_pred <- predict(svm.fit, newdata=OJ[-train,], type="class")
confusionMatrix(testing_pred,OJ[-train,]$Purchase)
```

(f) using radial
```{r}
tune.out <- tune(svm, Purchase ~ ., ranges=list(costs=costs), kernel="radial", data=OJ[train,], scale=FALSE, method="class")
tune.out$best.parameters
svm.fit <- svm(Purchase ~ ., kernel="radial", cost=tune.out$best.parameters$costs, data=OJ[train,], scale=FALSE, method="class")
training_pred <- predict(svm.fit, newdata=OJ[train,], type="class")
confusionMatrix(training_pred,OJ[train,]$Purchase)
testing_pred <- predict(svm.fit, newdata=OJ[-train,], type="class")
confusionMatrix(testing_pred,OJ[-train,]$Purchase)
```

(g) using polynomial of degree 2
```{r}
tune.out <- tune(svm, Purchase ~ ., ranges=list(costs=costs), kernel="polynomial", degree=2, data=OJ[train,], scale=FALSE, method="class")
tune.out$best.parameters
svm.fit <- svm(Purchase ~ ., kernel="polynomial", degree=2, cost=tune.out$best.parameters$costs, data=OJ[train,], scale=FALSE, method="class")
training_pred <- predict(svm.fit, newdata=OJ[train,], type="class")
confusionMatrix(training_pred,OJ[train,]$Purchase)
testing_pred <- predict(svm.fit, newdata=OJ[-train,], type="class")
confusionMatrix(testing_pred,OJ[-train,]$Purchase)
```

(h) best overall

EOF