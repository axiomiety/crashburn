---
title: "3.7 - Applied Exercises"
output:
  html_document:
    df_print: paged
---

# 8

## a

```{r}
library(ISLR2)
lm.fit <- lm(mpg ~ horsepower, data=Auto)
summary(lm.fit)
```

### Is there a relationship between the predictor and the response?

About 60% of the variance in `mpg` can be attributed to `horsepower` - and the F-statistic is such that we'd reject the null hypothesis (that is, there is no relationship)

### How strong is the relationship between the predictor and the response?

I'm not sure how to qualify "strong" - is that the slope? Because if so it isn't.

### Is the relationship between the predictor and the response positive or negative?

Negative - an increase in `horsepower` lowers `mpg`

### What is the predicted mpg associated with a horsepower of 98? What are the associated 95 % confidence and prediction intervals?

```{r}
predict(lm.fit, data.frame(horsepower=c(98)), interval = 'confidence')
predict(lm.fit, data.frame(horsepower=c(98)), interval = 'prediction')
```
As expected, the `prediction` interval is larger.

## b

```{r ggplot}
library(ggplot2)
ggplot(Auto, aes(x=horsepower, y=mpg)) + geom_point(size=2, shape=23) + geom_abline(intercept = lm.fit$coefficients[1], slope = lm.fit$coefficients[2], color="red")
```

## c

```{r plot}
plot(lm.fit)
```

Potential issues:
  - residuals aren't uniformly distributed, which suggests a non-linear relationship
  - the residuals vs leverage plot identifies some points that would impact the regression line if they were removed
  
```{r}
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data=Auto)
summary(lm.fit2)
```

```{r plot2}
plot(lm.fit2)
```

# 9

## a

```{r}
library(GGally)
ggpairs(subset(Auto, select=-c(name)), aes(colour=as.factor(origin)))
```

## b

```{r}
cor(subset(Auto, select=-c(name)))
```

## c

```{r}
lm.fit <- lm(mpg ~ ., data=subset(Auto, select=-c(name)))
summary(lm.fit)
```

There's a clear relationship between predictors and the response, with R^2 explaining 82% of the variance. 
Some predictors are not significant like `horsepower` or `acceleration`.
`year` is statistically siginifcant given the p-value.

## d

```{r}
plot(lm.fit)
```
The Residuals vs Leverage plot indicates a few observations with very high leverage.

TThe Residuals vs Fitted plot isn't uniform, indicating the true relationship is unlikely to be linear.

## e

```{r}
lm.fit_multi <- lm(mpg ~ .^2, data=subset(Auto, select=-c(name)))
summary(lm.fit_multi)
```

Note the difference in `R` with `*` and `:` (the former is additive + interaction, the other is interaction only).

Only acceleration and origin seem to be statistically significant?

## f

```{r}
lm.fit <- lm(mpg ~ weight + acceleration + displacement, data=subset(Auto, select=-c(name)))
summary(lm.fit)
lm.fit1 <- lm(mpg ~ weight + acceleration + I(log(displacement)), data=subset(Auto, select=-c(name)))
summary(lm.fit1)
```

`log` of displacement gives an increased R^2 - seems `acceleration` is fairly unsignificant!

# 10

## a

```{r}
library(ISLR2)
lm.fit <- lm(Sales ~ Price + Urban + US, data=Carseats)
summary(lm.fit)
```

## b

`Urban` and `US` are both qualitative.

`Price` is negatively correlated with sales, indicating a higher price doesn't lead to higher sales.

`US` is positive, indicating higher sales in US-based stores.

## c

$f(X) = 13.04 -0.54X_1 -0.022X_2 + 1.2X_3$

## d

We can reject the null hypothesis on all predictors except `Urban` as it's not statistically significant.

```{r}
summary(lm(Sales ~ Urban, data=Carseats))
```

## e

```{r}
lm.carseats2 <- lm(Sales ~ Price + US, data=Carseats)
summary(lm.carseats2)
```
Smaller RSE than with `Urban`

## f

Very poorly! We only explain about 24% of the variance.

## g

```{r}
confint(lm.carseats2)
```
## h

```{r}
plot(lm.carseats2)
```
There is some evidence of high leverage - but the Residuals vs Fitted plot is relatively uniform.

# 11

## a

```{r}
set.seed(1)
x <- rnorm(100)
y <- 2 * x + rnorm(100)
lm.fit <- lm(y ~ 0 + x)
summary(lm.fit)
```

## b

```{r}
set.seed(1)
x <- rnorm(100)
y <- 2 * x + rnorm(100)
lm.fit <- lm(x ~ 0 + y)
summary(lm.fit)
```

## c

$R^2$ is identical to the other way around! Residuals are smaller though - RSE is very different! (though I recall reading it's scale-dependent, so whilst it does look significant it isn't)

## d

```{r}
n <- length(x)
top <- sqrt(n-1) * sum(x*y)
bottom <- sqrt(sum(x^2)*sum(y^2)-sum(x*y)^2)
top/bottom
```

## e

## f

# 12

## a